{
  "groups": [
    {
      "name": "clip.model",
      "type": "com.imagesearch.search.config.ClipModelProperties",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    }
  ],
  "properties": [
    {
      "name": "clip.model.auto-download",
      "type": "java.lang.Boolean",
      "description": "Download models automatically if not found",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.embedding-dimension",
      "type": "java.lang.Integer",
      "description": "Embedding dimension (default: 512 for ViT-B\/32)",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.hugging-face-model-id",
      "type": "java.lang.String",
      "description": "Hugging Face model repository ID",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.image-model-path",
      "type": "java.lang.String",
      "description": "Path to CLIP image encoder ONNX model",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.image-size",
      "type": "java.lang.Integer",
      "description": "Image input size (CLIP default: 224x224)",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.inference-threads",
      "type": "java.lang.Integer",
      "description": "Number of threads for ONNX Runtime inference 0 = auto-detect based on CPU cores",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.max-text-length",
      "type": "java.lang.Integer",
      "description": "Maximum text sequence length (CLIP default: 77 tokens)",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.merges-path",
      "type": "java.lang.String",
      "description": "Path to CLIP merges file (BPE merges)",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.text-model-path",
      "type": "java.lang.String",
      "description": "Path to CLIP text encoder ONNX model",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.use-gpu",
      "type": "java.lang.Boolean",
      "description": "Enable GPU acceleration (requires ONNX Runtime GPU build)",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    },
    {
      "name": "clip.model.vocab-path",
      "type": "java.lang.String",
      "description": "Path to CLIP vocabulary file (BPE vocab)",
      "sourceType": "com.imagesearch.search.config.ClipModelProperties"
    }
  ],
  "hints": []
}